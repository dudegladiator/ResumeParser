{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/dudegladiator/ResumeParser"
      ],
      "metadata": {
        "id": "DeQ2xC7NLWwj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jwg30xVdCPUR"
      },
      "outputs": [],
      "source": [
        "!pip install spacy==3.7.2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from spacy.tokens import DocBin\n",
        "from tqdm import tqdm\n",
        "import random\n",
        "import json\n",
        "import spacy\n",
        "from spacy.util import filter_spans\n",
        "nlp = spacy.blank(\"en\") # load a new spacy model\n",
        "doc_bin = DocBin()\n",
        "\n",
        "\n",
        "!python -m spacy download en_core_web_lg"
      ],
      "metadata": {
        "id": "XOCnfV1DCZSj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def convert_dataturks_to_spacy(filepath, testing_data_proportion=0.2):\n",
        "    random.seed(0)\n",
        "    try:\n",
        "        all_data = []\n",
        "        with open(filepath, 'r') as f:\n",
        "            lines = f.readlines()\n",
        "\n",
        "        for line in lines:\n",
        "            line = line.lower()\n",
        "            data = json.loads(line)\n",
        "            text = data['content']\n",
        "            entities = []\n",
        "            data_annotations = data['annotation']\n",
        "            if data_annotations is not None:\n",
        "                for annotation in data_annotations:\n",
        "                    # only a single point in text annotation.\n",
        "                    point = annotation['points'][0]\n",
        "                    labels = annotation['label']\n",
        "                    # handle both list of labels or a single label.\n",
        "                    if not isinstance(labels, list):\n",
        "                        labels = [labels]\n",
        "\n",
        "                    for label in labels:\n",
        "                        point_start = point['start']\n",
        "                        point_end = point['end']\n",
        "                        point_text = point['text']\n",
        "\n",
        "                        lstrip_diff = len(point_text) - len(point_text.lstrip())\n",
        "                        rstrip_diff = len(point_text) - len(point_text.rstrip())\n",
        "                        if lstrip_diff != 0:\n",
        "                            point_start = point_start + lstrip_diff\n",
        "                        if rstrip_diff != 0:\n",
        "                            point_end = point_end - rstrip_diff\n",
        "                        entities.append((point_start, point_end + 1, label))\n",
        "            all_data.append((text, {\"entities\": entities}))\n",
        "        training_data = [data for data in all_data ]\n",
        "        return training_data\n",
        "\n",
        "    except Exception as e:\n",
        "        print(\"Error occurred: \", str(e))"
      ],
      "metadata": {
        "id": "det78UMKvvJp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#start with harini dataset\n",
        "train_data = convert_dataturks_to_spacy(\"/content/model3_dataset.json\")"
      ],
      "metadata": {
        "id": "7xw8bHFjvvHB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_data = []\n",
        "for example in train_data:\n",
        "  temp_dict = {}\n",
        "  temp_dict['text'] = example[0]\n",
        "  temp_dict['entities'] = []\n",
        "  for annotation in example[1][\"entities\"]:\n",
        "    if annotation[2] == '' or annotation[2] is None or annotation[2] == 'UNKNOWN':\n",
        "      label = 'ignore'\n",
        "    start = annotation[0]\n",
        "    end = annotation[1]\n",
        "    label = annotation[2].upper()\n",
        "    temp_dict['entities'].append((start, end, label))\n",
        "  training_data.append(temp_dict)\n",
        "\n",
        "print(training_data[0])"
      ],
      "metadata": {
        "id": "eqNOvmrYvvER"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "count=0\n",
        "for training_example  in tqdm(training_data):\n",
        "    text = training_example['text']\n",
        "    labels = training_example['entities']\n",
        "    doc = nlp.make_doc(text)\n",
        "    ents = []\n",
        "    for start, end, label in labels:\n",
        "        if label == 'ignore':\n",
        "          continue\n",
        "        span = doc.char_span(start, end, label=label, alignment_mode=\"expand\")\n",
        "        if span is None:\n",
        "            print(\"Skipping entity\")\n",
        "            print(start, end, label)\n",
        "            count+=1\n",
        "        else:\n",
        "            ents.append(span)\n",
        "    filtered_ents = filter_spans(ents)\n",
        "    doc.ents = filtered_ents\n",
        "    doc_bin.add(doc)\n",
        "print(count)\n",
        "doc_bin.to_disk(\"model3.spacy\")"
      ],
      "metadata": {
        "id": "Qb0B3M9DvvBp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Please get the base config file from spacy website"
      ],
      "metadata": {
        "id": "OELeJWfh_ijp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy init fill-config base_config.cfg config.cfg"
      ],
      "metadata": {
        "id": "hW7lCRfgvu-5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you get the config file, then directly run below code\n",
        "\n",
        "---\n",
        "\n",
        "Upload the config file to root\n"
      ],
      "metadata": {
        "id": "-hKM6R_8_nxb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy train config.cfg --output ./output3 --paths.train ./model3.spacy --paths.dev ./model3.spacy"
      ],
      "metadata": {
        "id": "lR-aGl01xhI6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "go to the ouput3 folder, model-best is model3"
      ],
      "metadata": {
        "id": "myQUmVGaBklT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model3 = spacy.load(\"/content/output3/model-best\")"
      ],
      "metadata": {
        "id": "yvipvL22D7ot"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model3.get_pipe(\"ner\").labels"
      ],
      "metadata": {
        "id": "Q_M-k-B_EAuW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}